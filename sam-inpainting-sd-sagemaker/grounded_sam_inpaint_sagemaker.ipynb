{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bb81392-8d64-43c5-bfab-87d03a3bdbf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Change background using Grouded SAM and Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0965e8-29b8-411f-a2b0-c9628e5f8c70",
   "metadata": {},
   "source": [
    "在本节实验中，我们将会部署 Grounded SAM 和 Stable diffusion 2 inpainting model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6841d88b-a330-4e6f-b2be-ab26266f816d",
   "metadata": {},
   "source": [
    "Grounded SAM 用于根据提示词来找到对象所在的位置，然后进行语义分割，对物体背景进行蒙版（MASK）。然后将蒙版后的图片给到 SD inpainting 模型进行局部重绘，实现背景的替换"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0cc8ad-13cd-45d5-b1be-68537bd2c6d8",
   "metadata": {},
   "source": [
    "## Deploy Grounded Segment Anything"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b4bcc2-17c1-4032-acf3-4dc92bee9193",
   "metadata": {},
   "source": [
    ">注意：执行单元格代码框后，若左侧中括号中的符号为'*'，表示代码正在运行过程中；若为数字，则表示代码已执行完成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3575699b-ad2d-43ae-b5aa-c485953627a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# init sagemaker parameters\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import serializers, deserializers\n",
    "from sagemaker.pytorch.model import PyTorchModel, PyTorchPredictor\n",
    "\n",
    "role = sagemaker.get_execution_role()  # execution role for the endpoint\n",
    "sess = sagemaker.session.Session()  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # bucket to house artifacts\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "account_id = sess.account_id()  # account_id of the current SageMaker Studio environment\n",
    "\n",
    "s3_model_prefix = \"east-ai-models/grounded-sam\"\n",
    "\n",
    "print(f\"role: {role}\")\n",
    "print(f\"bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2916b7-f31a-4e67-80ea-a4e38b60a6a2",
   "metadata": {},
   "source": [
    "##### 压缩 dummy 文件并上传至 S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cae79b-94f8-4a63-a477-2902d80e19ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compress dummy model and upload to S3\n",
    "!touch dummy\n",
    "!rm -f model.tar.gz\n",
    "!tar czvf model.tar.gz dummy\n",
    "s3_model_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_model_prefix)\n",
    "print(f\"S3 Code or Model tar uploaded to --- > {s3_model_artifact}\")\n",
    "!rm -f dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b67759-719f-43d1-939f-f5b373072da5",
   "metadata": {},
   "source": [
    "#### Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305f344-24e8-4b43-89ff-153d72f5e426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "framework_version = '2.0.1'\n",
    "py_version = 'py310'\n",
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "endpoint_name =\"grounded-sam\"\n",
    "\n",
    "model = PyTorchModel(\n",
    "    model_data = s3_model_artifact,\n",
    "    entry_point = 'inference.py',\n",
    "    source_dir = \"./code/\",\n",
    "    role = role,\n",
    "    framework_version = framework_version, \n",
    "    py_version = py_version,\n",
    ")\n",
    "\n",
    "print(\"模型部署过程大约需要 7~8 分钟，请等待\" + \".\"*20)\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    ")\n",
    "\n",
    "print(\"模型部署已完成，可以继续执行后续步骤\" + \".\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77edc2d6-26c6-448a-8684-34d8ed391356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "sam_predictor = PyTorchPredictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9497dc92-8f70-4194-bf08-6fa3bf397af2",
   "metadata": {},
   "source": [
    "## Deploy inpainting stable diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d079ea-9144-4bd6-9e35-f66959bf703b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s3_code_prefix = \"east-ai-models/inpainting-sd/accelerate\"\n",
    "\n",
    "!mkdir inpaintmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493d840-b36d-4946-ab04-c3639c0e2d9b",
   "metadata": {},
   "source": [
    "#### Writing SageMaker LMI code properties and model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a8acf2-be5a-41e0-82e3-643993398b13",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./inpaintmodel/requirements.txt\n",
    "transformers\n",
    "diffusers==0.17.0\n",
    "omegaconf\n",
    "accelerate\n",
    "boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ced649-5ea0-4462-a5df-ca6aa851af0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./inpaintmodel/serving.properties\n",
    "engine=Python\n",
    "option.model_id=stabilityai/stable-diffusion-2-inpainting\n",
    "option.tensor_parallel_degree=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69217902-a1d0-42eb-a216-98b186fc607d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile ./inpaintmodel/model.py\n",
    "from djl_python import Input, Output\n",
    "import os\n",
    "import torch\n",
    "from typing import Any, Dict, Tuple\n",
    "import warnings\n",
    "from diffusers import DiffusionPipeline\n",
    "from diffusers import StableDiffusionInpaintPipeline\n",
    "from diffusers import EulerDiscreteScheduler, EulerAncestralDiscreteScheduler, HeunDiscreteScheduler, LMSDiscreteScheduler, KDPM2DiscreteScheduler, KDPM2AncestralDiscreteScheduler,DDIMScheduler\n",
    "import io\n",
    "from PIL import Image\n",
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "from torch import autocast\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = None\n",
    "\n",
    "def image_read(image_file):\n",
    "    return Image.open(image_file).convert(\"RGB\")\n",
    "\n",
    "\n",
    "def mask_read(mask_file):\n",
    "    return Image.open(mask_file).convert('1') \n",
    "    \n",
    "    \n",
    "def image_fuser(new_image_lst, org_image, mask):\n",
    "    results = []\n",
    "    for new_image in new_image_lst:\n",
    "        new_image = np.array(new_image)\n",
    "        org_image = np.array(org_image)\n",
    "        mask = np.array(mask)\n",
    "        org_image[mask] = new_image[mask]\n",
    "        results.append(Image.fromarray(org_image))\n",
    "    return results\n",
    "\n",
    "\n",
    "def generate_image(image, mask, prompt, negative_prompt, generator, pipe, num_inference_steps, num_images_per_prompt):\n",
    "    # resize for inpainting \n",
    "    w, h = image.size\n",
    "    in_image = image.resize((512, 512))\n",
    "    in_mask = mask.resize((512, 512))\n",
    "    image_gen = pipe(image=in_image, mask_image=in_mask, prompt=prompt, negative_prompt=negative_prompt, generator=generator, num_inference_steps=num_inference_steps, num_images_per_prompt=num_images_per_prompt).images\n",
    "    results = image_fuser(image_gen, in_image, in_mask)\n",
    "    results = [r.resize((w, h)) for r in results]\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_model(properties):\n",
    "    print(properties)\n",
    "    model_name = properties[\"model_id\"]\n",
    "    model = StableDiffusionInpaintPipeline.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "    model = model.to(\"cuda\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def handle(inputs: Input) -> None:\n",
    "    global model\n",
    "    print(\"print inputs: \" + str(inputs) + '.'*20)\n",
    "    \n",
    "    if not model:\n",
    "        model = get_model(inputs.get_properties())\n",
    "    \n",
    "    samplers = {\n",
    "        \"euler_a\": EulerAncestralDiscreteScheduler,\n",
    "        \"eular\": EulerDiscreteScheduler,\n",
    "        \"heun\": HeunDiscreteScheduler,\n",
    "        \"lms\": LMSDiscreteScheduler,\n",
    "        \"dpm2\": KDPM2DiscreteScheduler,\n",
    "        \"dpm2_a\": KDPM2AncestralDiscreteScheduler,\n",
    "        \"ddim\": DDIMScheduler\n",
    "    }\n",
    "\n",
    "    if inputs.is_empty():\n",
    "        # Model server makes an empty call to warmup the model on startup\n",
    "        return None\n",
    "    \n",
    "    input_data = inputs.get_as_json()\n",
    "    \n",
    "    dir_lst = input_data['input_image'].split('/')\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_response_object = s3_client.get_object(Bucket=dir_lst[2], Key='/'.join(dir_lst[3:]))\n",
    "    img_bytes = s3_response_object['Body'].read()\n",
    "    org_image = image_read(io.BytesIO(img_bytes))\n",
    "    \n",
    "    dir_lst = input_data['input_mask_image'].split('/')\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_response_object = s3_client.get_object(Bucket=dir_lst[2], Key='/'.join(dir_lst[3:]))\n",
    "    img_bytes = s3_response_object['Body'].read()\n",
    "    seg_mask = mask_read(io.BytesIO(img_bytes))\n",
    "    \n",
    "    if input_data['seed'] == -1:\n",
    "        generator = torch.Generator(device='cuda').manual_seed(random.randint(1, 10000000))\n",
    "    else:\n",
    "        generator = torch.Generator(device='cuda').manual_seed(input_data['seed'])\n",
    "    \n",
    "    model.scheduler = samplers[input_data[\"sampler\"]].from_config(model.scheduler.config)\n",
    "    \n",
    "    inpaint_prompt = input_data['prompt']\n",
    "    inpaint_negative_prompt = input_data['negative_prompt']\n",
    "    num_inference_steps = input_data['steps']\n",
    "    num_images_per_prompt = input_data['count']\n",
    "    inpainted_images = generate_image(org_image, seg_mask, inpaint_prompt, inpaint_negative_prompt, generator, model, num_inference_steps, num_images_per_prompt)\n",
    "    print(\"Prediction Complete\" + '.'*20)\n",
    "    \n",
    "    res = {'images': []}\n",
    "    for image in inpainted_images:\n",
    "        byteImgIO = io.BytesIO()\n",
    "        image.save(byteImgIO, \"WEBP\")\n",
    "        byteImgIO.seek(0)\n",
    "        byteImg = byteImgIO.read()\n",
    "        imgstr = base64.b64encode(byteImg).decode('ascii')\n",
    "        res['images'].append(imgstr)\n",
    "        \n",
    "    return Output().add(json.dumps(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf29060-c1c0-49f5-8354-17b282fa667c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compress code and upload to S3\n",
    "!rm -f model.tar.gz\n",
    "!rm -rf inpaintmodel/.ipynb_checkpoints\n",
    "!tar czvf model.tar.gz -C inpaintmodel .\n",
    "s3_code_artifact = sess.upload_data(\"model.tar.gz\", bucket, s3_code_prefix)\n",
    "print(f\"S3 Code or Model tar uploaded to --- > {s3_code_artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e867bff-b0be-4ab7-ad84-7fb8027f53b8",
   "metadata": {},
   "source": [
    "#### Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4517aa0-ecf2-45c4-8b79-d12b0f8e1fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# retrieve SageMaker LMI container image URI\n",
    "from sagemaker import Model\n",
    "\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"djl-deepspeed\", region=region, version=\"0.23.0\"\n",
    ")\n",
    "\n",
    "\n",
    "print(image_uri)\n",
    "\n",
    "model = Model(image_uri=image_uri, model_data=s3_code_artifact, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fe0519-de05-42b3-9e14-727872b2e843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.g4dn.xlarge\"\n",
    "\n",
    "endpoint_name = \"inpainting-sd\"\n",
    "\n",
    "print(\"模型部署过程大约需要 7~8 分钟，请等待\" + \".\"*20)\n",
    "\n",
    "model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    container_startup_health_check_timeout=900,\n",
    ")\n",
    "\n",
    "print(\"模型部署已完成，可以继续执行后续步骤\" + \".\"*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a9b4de-ce22-48e5-b0ac-8f3e8f525f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our requests and responses will be in json format so we specify the serializer and the deserializer\n",
    "sd_predictor = sagemaker.Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    "    serializer=serializers.JSONSerializer(),\n",
    "    deserializer=deserializers.JSONDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb0af45-ad05-4837-9416-4e0730487422",
   "metadata": {},
   "source": [
    "## Prediction(Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cb856f-ef1b-44eb-8d79-8edd6587eac9",
   "metadata": {},
   "source": [
    "#### Predict using grounded_sam to generate mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021c9d56-cc9d-41aa-9502-3f4f0dee6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将 <object_uuid> 替换为上一节 notebook（product_design_sd.ipynb）中推理部分生成的其中一张图片的名称\n",
    "input_image_path = 's3://{}/product-design-output/<object_uuid>.webp'.format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2133e9-821e-42cc-95fd-e25543687e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# generate mask image to s3\n",
    "input_data = {\n",
    "                'input_image': input_image_path,\n",
    "                'prompt': 'tent',\n",
    "                'output_mask_image_dir': 's3://{}/mask-images/'.format(bucket)\n",
    "             }\n",
    "\n",
    "mask_res = sam_predictor.predict(input_data)\n",
    "mask_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a902dad-071c-49de-8843-ac05f5e94142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 查看 mask 后的图片\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "dir_lst = mask_res['result'].split('/')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_response_object = s3_client.get_object(Bucket=dir_lst[2], Key='/'.join(dir_lst[3:]))\n",
    "img_bytes = s3_response_object['Body'].read()\n",
    "Image.open(io.BytesIO(img_bytes)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d9462b-9ca4-47c3-9bb5-b030ee048f49",
   "metadata": {},
   "source": [
    "#### Predict using inpainting SD model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa3e2fe-b99d-4689-8300-f9f8ac3f4e19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "def predict_fn(predictor, inputs):\n",
    "    response = predictor.predict(inputs)\n",
    "    for image in response['images']:\n",
    "        dataBytesIO = io.BytesIO(base64.b64decode(image))\n",
    "        image = Image.open(dataBytesIO)\n",
    "        display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5b9fc-be25-4bc7-bc3d-eb5a88426e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"prompt\": \"tent on the ground, mountain and snow, high quality, 4k\",\n",
    "    \"negative_prompt\": \"(deformed iris, deformed pupils, semi-realistic, cgi, 3d, render, sketch, cartoon, drawing, anime:1.4), text, close up, cropped, out of frame, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, mutation, deformed, blurry, dehydrated, bad anatomy, bad proportions, disfigured, gross proportions\",\n",
    "    \"input_image\": input_image_path,\n",
    "    \"input_mask_image\": mask_res['result'],\n",
    "    \"steps\": 30,\n",
    "    \"sampler\": \"ddim\",\n",
    "    \"seed\": -1,\n",
    "    \"count\": 2\n",
    "}\n",
    "\n",
    "predict_fn(sd_predictor, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8079ed-56a5-4bc6-93a6-3cc408a14996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
